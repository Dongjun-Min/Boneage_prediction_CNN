{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "def show(img):   \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('dark_background')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0],True)\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto,InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  3 17:18:42 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   54C    P0   126W / 300W |  10516MiB / 32480MiB |     92%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\n",
      "| N/A   43C    P0    55W / 300W |   1001MiB / 32480MiB |      6%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     52069      C   ...aconda3/envs/tensorflow2_p36/bin/python  1459MiB |\n",
      "|    0     80683      C   ...aconda3/envs/tensorflow2_p36/bin/python  9047MiB |\n",
      "|    1     52069      C   ...aconda3/envs/tensorflow2_p36/bin/python   315MiB |\n",
      "|    1     80683      C   ...aconda3/envs/tensorflow2_p36/bin/python   307MiB |\n",
      "|    1     88885      C   /home/centos/anaconda3/bin/python            369MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "print(os.popen('nvidia-smi').read())\n",
    "\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.applications.ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, img 불러오고 model화 시키기 전 전처리과정\n",
    "img_size = 224\n",
    "model_weight = \"resnet101_roi.h5\"\n",
    "\n",
    "df_path = \"..\"\n",
    "img_path = \"20200728_Carpal Bone ROI_filter\"\n",
    "\n",
    "\n",
    "df = pd.read_excel(df_path+\"/BA_Total.xlsx\")\n",
    "l = len(df)\n",
    "\n",
    "file_name = np.array([\"{0:03d}_05_02.jpg\".format(i+1) for i in range(l)])\n",
    "\n",
    "df['boneage'] = df.BA*12\n",
    "ba_mean = df.boneage.mean()\n",
    "ba_std = df.boneage.std()\n",
    "df[\"BA_z\"] = (df.boneage-ba_mean)/ba_std\n",
    "df.filename = file_name\n",
    "df[\"gender\"] = df[\"성별\"]%2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(218)\n",
    "df = df.reset_index(drop=True)\n",
    "train_df, val_df = train_test_split(df, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_generator(df):\n",
    "    gender_in = np.array(df.gender)\n",
    "    img_in = []\n",
    "    age = np.array(df.BA_z)\n",
    "    \n",
    "    for file_path in df.filename:\n",
    "        img = cv2.imread(img_path+'/'+file_path)\n",
    "        small = cv2.resize(img, (img_size,img_size),cv2.INTER_AREA)\n",
    "        img_in.append(small)\n",
    "        \n",
    "    img_in = np.array(img_in)\n",
    "        \n",
    "    \n",
    "    return [gender_in,img_in],age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process시각화 및 손실함수\n",
    "\n",
    "def plot_it(history):\n",
    "    '''function to plot training and validation error'''\n",
    "    fig, ax = plt.subplots( figsize=(20,10))\n",
    "    ax.plot(history.history['mae_in_months'])\n",
    "    ax.plot(history.history['val_mae_in_months'])\n",
    "    plt.title('Model Error')\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    ax.grid(color='black')\n",
    "    plt.show()\n",
    "\n",
    "from tensorflow.keras.metrics import mean_absolute_error\n",
    "\n",
    "def mae_in_months(x_p, y_p):\n",
    "    '''function to return mae in months'''\n",
    "    return mean_absolute_error((ba_std*x_p + ba_mean), (ba_std*y_p + ba_mean)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "# tf.keras.applications.resnet50.ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171450368/171446536 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "img_size = 224\n",
    "g_input = Input(shape = (1,))\n",
    "g_output = Dense(64,activation = 'relu')(g_input)\n",
    "\n",
    "g_model = Model(inputs = g_input,outputs = g_output)\n",
    "\n",
    "model_1 = tf.keras.applications.resnet.ResNet101(input_shape = (img_size, img_size, 3),\n",
    "                                               include_top = False,\n",
    "                                               weights = 'imagenet')\n",
    "model_1.trainable = True\n",
    "model_2 = Sequential()\n",
    "model_2.add(model_1)\n",
    "model_2.add(GlobalMaxPooling2D())\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(2048, activation = 'relu'))\n",
    "\n",
    "\n",
    "\n",
    "con = concatenate([g_model.output, model_2.output])\n",
    "dense1 = Dense(1024,activation='relu')(con)\n",
    "# batch = BatchNormalization()(dense1)\n",
    "# drop = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(512,activation='relu')(dense1)\n",
    "# dense3 = Dense(10,activation='softmax')(dense2)\n",
    "model_out = Dense(1,activation = \"linear\")(dense2)\n",
    "\n",
    "model = Model([g_input,model_2.input],model_out)\n",
    "model.compile(loss ='mse', optimizer= 'adam', metrics = [mae_in_months] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet101\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 14, 14, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 14, 14, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 14, 14, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 14, 14, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 14, 14, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 14, 14, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 14, 14, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 14, 14, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 14, 14, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 14, 14, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 14, 14, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 14, 14, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 14, 14, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 14, 14, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 14, 14, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 14, 14, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 14, 14, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 14, 14, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 14, 14, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 14, 14, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 14, 14, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 14, 14, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 14, 14, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 14, 14, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 14, 14, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 14, 14, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 14, 14, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 14, 14, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 14, 14, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 14, 14, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 14, 14, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 14, 14, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 14, 14, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 14, 14, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 14, 14, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 14, 14, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 14, 14, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 42,658,176\n",
      "Trainable params: 42,552,832\n",
      "Non-trainable params: 105,344\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_y = multi_generator(train_df)\n",
    "val_X, val_y = multi_generator(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  3 11:44:25 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   34C    P0    55W / 300W |   1019MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\n",
      "| N/A   37C    P0    53W / 300W |   9069MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     86270      C   /home/centos/anaconda3/bin/python           1009MiB |\n",
      "|    1     84632      C   /home/centos/anaconda3/bin/python           9059MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 8s 785ms/step - loss: 5973.0483 - mae_in_months: 533.7286 - val_loss: 513100.1562 - val_mae_in_months: 9858.4336 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 3.1347 - mae_in_months: 22.6840 - val_loss: 70711024.0000 - val_mae_in_months: 144712.0938 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 5s 544ms/step - loss: 1.7419 - mae_in_months: 18.5831 - val_loss: 373819.0312 - val_mae_in_months: 10575.3525 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 5s 527ms/step - loss: 0.8162 - mae_in_months: 12.5955 - val_loss: 14715.4902 - val_mae_in_months: 2011.8447 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 6s 593ms/step - loss: 1.0940 - mae_in_months: 15.3857 - val_loss: 551.4442 - val_mae_in_months: 379.3638 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 0.5796 - mae_in_months: 10.7803 - val_loss: 1429.9967 - val_mae_in_months: 609.3520 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 6s 618ms/step - loss: 0.5179 - mae_in_months: 10.0710 - val_loss: 537.5170 - val_mae_in_months: 372.2428 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.4481 - mae_in_months: 9.6195 - val_loss: 78.1167 - val_mae_in_months: 131.5425 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.3170 - mae_in_months: 7.7597 - val_loss: 64.1936 - val_mae_in_months: 129.0416 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 5s 511ms/step - loss: 0.3390 - mae_in_months: 8.1814 - val_loss: 1.6287 - val_mae_in_months: 18.1726 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.3020 - mae_in_months: 7.8063 - val_loss: 17.7912 - val_mae_in_months: 64.3653 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.2118 - mae_in_months: 6.5850 - val_loss: 18.0063 - val_mae_in_months: 63.3105 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.1829 - mae_in_months: 6.1207 - val_loss: 4.2846 - val_mae_in_months: 29.4859 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.1396 - mae_in_months: 5.2635 - val_loss: 6.4318 - val_mae_in_months: 36.7825 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 5s 526ms/step - loss: 0.2030 - mae_in_months: 6.4167 - val_loss: 0.5052 - val_mae_in_months: 10.2062 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.0901 - mae_in_months: 4.0630 - val_loss: 0.5450 - val_mae_in_months: 10.1442 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 0.0641 - mae_in_months: 3.5789 - val_loss: 0.4781 - val_mae_in_months: 9.5925 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.0584 - mae_in_months: 3.3955 - val_loss: 0.5351 - val_mae_in_months: 10.1818 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 0.0877 - mae_in_months: 3.9583 - val_loss: 1.6224 - val_mae_in_months: 18.0823 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.1983 - mae_in_months: 6.3503 - val_loss: 0.5182 - val_mae_in_months: 10.7345 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 0.0932 - mae_in_months: 4.4412 - val_loss: 0.5843 - val_mae_in_months: 10.7733 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 6s 583ms/step - loss: 0.0612 - mae_in_months: 3.4293 - val_loss: 0.4009 - val_mae_in_months: 9.0158 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 6s 577ms/step - loss: 0.1052 - mae_in_months: 4.6147 - val_loss: 0.3187 - val_mae_in_months: 8.2613 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.1260 - mae_in_months: 5.1825 - val_loss: 0.6848 - val_mae_in_months: 11.8985 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 6s 579ms/step - loss: 0.0828 - mae_in_months: 4.2644 - val_loss: 0.2644 - val_mae_in_months: 7.6129 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 0.1149 - mae_in_months: 4.9519 - val_loss: 0.4591 - val_mae_in_months: 9.5725 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.0811 - mae_in_months: 4.0126 - val_loss: 0.2997 - val_mae_in_months: 8.1787 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.0648 - mae_in_months: 3.5846 - val_loss: 0.3351 - val_mae_in_months: 8.3143 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 0.1008 - mae_in_months: 4.3758 - val_loss: 0.2528 - val_mae_in_months: 7.2063 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.0357 - mae_in_months: 2.6869 - val_loss: 0.2531 - val_mae_in_months: 7.2459 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 5s 544ms/step - loss: 0.0234 - mae_in_months: 2.1857 - val_loss: 0.2320 - val_mae_in_months: 6.9250 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.0831 - mae_in_months: 4.3063 - val_loss: 0.2467 - val_mae_in_months: 7.0222 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.0285 - mae_in_months: 2.4737 - val_loss: 0.2547 - val_mae_in_months: 7.0865 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.0253 - mae_in_months: 2.2034 - val_loss: 0.2733 - val_mae_in_months: 7.5172 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.0512 - mae_in_months: 3.2680 - val_loss: 0.3448 - val_mae_in_months: 8.3893 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 0.0369 - mae_in_months: 2.8432 - val_loss: 0.1944 - val_mae_in_months: 6.1711 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 0.0480 - mae_in_months: 3.0034 - val_loss: 0.2982 - val_mae_in_months: 7.6922 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.0439 - mae_in_months: 2.9684 - val_loss: 0.2350 - val_mae_in_months: 7.1435 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.0389 - mae_in_months: 2.7802 - val_loss: 0.2192 - val_mae_in_months: 6.4766 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0348 - mae_in_months: 2.6493 - val_loss: 0.1901 - val_mae_in_months: 6.2318 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.0203 - mae_in_months: 2.0577 - val_loss: 0.1961 - val_mae_in_months: 6.1431 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.0157 - mae_in_months: 1.7572 - val_loss: 0.1927 - val_mae_in_months: 6.2269 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.0248 - mae_in_months: 2.1736 - val_loss: 0.2125 - val_mae_in_months: 6.5838 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.0131 - mae_in_months: 1.5608 - val_loss: 0.1976 - val_mae_in_months: 6.2162 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.0246 - mae_in_months: 2.2550 - val_loss: 0.2049 - val_mae_in_months: 6.3800 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.0164 - mae_in_months: 1.7934 - val_loss: 0.1849 - val_mae_in_months: 6.1564 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.0231 - mae_in_months: 2.1944 - val_loss: 0.1924 - val_mae_in_months: 6.2634 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.0085 - mae_in_months: 1.2739 - val_loss: 0.1955 - val_mae_in_months: 6.1787 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.0276 - mae_in_months: 2.3912 - val_loss: 0.1984 - val_mae_in_months: 6.3147 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.0118 - mae_in_months: 1.5392 - val_loss: 0.2055 - val_mae_in_months: 6.4112 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 6s 551ms/step - loss: 0.0135 - mae_in_months: 1.6691 - val_loss: 0.1823 - val_mae_in_months: 6.1740 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.0115 - mae_in_months: 1.5328 - val_loss: 0.1903 - val_mae_in_months: 6.2534 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.0160 - mae_in_months: 1.8364 - val_loss: 0.1858 - val_mae_in_months: 6.2098 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 0.0213 - mae_in_months: 2.0655 - val_loss: 0.1992 - val_mae_in_months: 6.4016 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 0.0106 - mae_in_months: 1.4352 - val_loss: 0.1829 - val_mae_in_months: 6.0679 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 0.0107 - mae_in_months: 1.4111 - val_loss: 0.2013 - val_mae_in_months: 6.4317 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 2s 180ms/step - loss: 0.0075 - mae_in_months: 1.2146 - val_loss: 0.1899 - val_mae_in_months: 6.3268 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 0.0099 - mae_in_months: 1.3900 - val_loss: 0.1842 - val_mae_in_months: 6.0721 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.0120 - mae_in_months: 1.5701 - val_loss: 0.1982 - val_mae_in_months: 6.4304 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.0101 - mae_in_months: 1.4100 - val_loss: 0.1939 - val_mae_in_months: 6.2792 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.0107 - mae_in_months: 1.4012 - val_loss: 0.1824 - val_mae_in_months: 6.0853 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 fit\n",
    "\n",
    "epochs = 100\n",
    "#early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience= 10,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "mc = ModelCheckpoint(model_weight, monitor='val_loss', mode='min', save_best_only=True)\n",
    "rLR = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 검증 손실을 기준으로 callback이 호출됩니다\n",
    "    factor=0.5,          # callback 호출시 학습률을 1/2로 줄입니다\n",
    "    patience=10,         # epoch 10 동안 개선되지 않으면 callback이 호출됩니다\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping,mc,rLR]\n",
    "\n",
    "\n",
    "#fit model\n",
    "history = model.fit(train_X,train_y,\n",
    "                    validation_data = (val_X,val_y),\n",
    "                    epochs = epochs,\n",
    "                    callbacks= callbacks)\n",
    "plot_it(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  3 11:48:24 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   38C    P0    55W / 300W |   9069MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\n",
      "| N/A   51C    P0   176W / 300W |  17261MiB / 32480MiB |     86%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     86270      C   /home/centos/anaconda3/bin/python           9059MiB |\n",
      "|    1     84632      C   /home/centos/anaconda3/bin/python          17251MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(os.popen('nvidia-smi').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1823 - mae_in_months: 6.1740\n",
      "mae_year : 0.5144990682601929, mse : 0.015188770989576975,r2_score : 0.798997123042773\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(val_X)*ba_std+ba_mean\n",
    "mse, mae = model.evaluate(val_X,val_y)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(val_df.boneage,pred)\n",
    "print(f\"mae_year : {mae/12}, mse : {mse/12},r2_score : {r2}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>roi</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xception++</td>\n",
       "      <td>1.540548</td>\n",
       "      <td>17.096090</td>\n",
       "      <td>-180.695600</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg-ba</td>\n",
       "      <td>1.160614</td>\n",
       "      <td>0.073136</td>\n",
       "      <td>-0.303073</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg-ba</td>\n",
       "      <td>0.670392</td>\n",
       "      <td>0.025254</td>\n",
       "      <td>-0.570250</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xception++</td>\n",
       "      <td>0.557815</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>-0.361841</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pre xception++</td>\n",
       "      <td>0.639215</td>\n",
       "      <td>0.022091</td>\n",
       "      <td>-1.055396</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xception+gender</td>\n",
       "      <td>0.551765</td>\n",
       "      <td>0.017635</td>\n",
       "      <td>0.766628</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pre-xception+gender</td>\n",
       "      <td>0.600951</td>\n",
       "      <td>0.020432</td>\n",
       "      <td>0.729614</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tjnet-gender2</td>\n",
       "      <td>0.407535</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.874158</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tjnet_kaggle.h5</td>\n",
       "      <td>0.929146</td>\n",
       "      <td>0.011265</td>\n",
       "      <td>0.870070</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resnet_roi.h5</td>\n",
       "      <td>0.564176</td>\n",
       "      <td>0.016662</td>\n",
       "      <td>0.779505</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tjnet_roi.h5</td>\n",
       "      <td>0.418141</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>0.865863</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resnet50v2_roi.h5</td>\n",
       "      <td>0.631021</td>\n",
       "      <td>0.023502</td>\n",
       "      <td>0.688984</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>resnet151v2_roi.h5</td>\n",
       "      <td>0.560760</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.757090</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>resnet101v2_roi.h5</td>\n",
       "      <td>0.592493</td>\n",
       "      <td>0.018669</td>\n",
       "      <td>0.752937</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>resnet101_roi.h5</td>\n",
       "      <td>0.514499</td>\n",
       "      <td>0.015189</td>\n",
       "      <td>0.798997</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model       mae        mse    r2_score    roi  class\n",
       "0            xception++  1.540548  17.096090 -180.695600  False  False\n",
       "1                vgg-ba  1.160614   0.073136   -0.303073  False  False\n",
       "2                vgg-ba  0.670392   0.025254   -0.570250   True  False\n",
       "3            xception++  0.557815   0.016407   -0.361841   True  False\n",
       "4        pre xception++  0.639215   0.022091   -1.055396   True  False\n",
       "5       xception+gender  0.551765   0.017635    0.766628   True  False\n",
       "6   pre-xception+gender  0.600951   0.020432    0.729614   True  False\n",
       "7         tjnet-gender2  0.407535   0.009509    0.874158   True  False\n",
       "8       tjnet_kaggle.h5  0.929146   0.011265    0.870070   True  False\n",
       "9         resnet_roi.h5  0.564176   0.016662    0.779505   True  False\n",
       "10         tjnet_roi.h5  0.418141   0.010136    0.865863   True  False\n",
       "11    resnet50v2_roi.h5  0.631021   0.023502    0.688984   True  False\n",
       "12   resnet151v2_roi.h5  0.560760   0.018355    0.757090   True  False\n",
       "13   resnet101v2_roi.h5  0.592493   0.018669    0.752937   True  False\n",
       "14     resnet101_roi.h5  0.514499   0.015189    0.798997   True  False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_csv(\"result.csv\")\n",
    "result_df.loc[len(result_df)]=(model_weight,mae/12,mse/12,r2,True,False)\n",
    "result_df.to_csv(\"result.csv\",index=False)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
